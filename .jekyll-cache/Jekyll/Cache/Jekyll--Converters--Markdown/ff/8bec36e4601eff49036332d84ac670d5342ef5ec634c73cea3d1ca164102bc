I"Ii<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vT8PsgoYD97P7ZvBxpVM3aCGnxX7A5_3o_ep7CqbsbGbuq7-MWdeCIRbNUvqfyJYuRliseB9j0DuqeE/embed?start=false&amp;loop=true&amp;delayms=3000" frameborder="0" width="700" height="423" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

<p>This article mainly introduces the full picture of a data analysis pipeline by showing the simple data import, feature engineering, and exploratory data analysis processes. The data used this time is relatively clean, so basically no data cleaning has been performed except for the analysis part of this article.</p>

<p>The entire working process is divided into three parts: 10-read-in, 20-feature-engineering, 30-exploratory-data-analysis.</p>

<h2 id="10-read-in">10-read-in</h2>

<h4 id="import-libraries">Import libraries.</h4>

<pre><code class="language-{r}">library(readxl)
library(tidyverse)
library(janitor)
library(ggplot2)
library(tidytext)
library(wordcloud2)
library(RColorBrewer)
</code></pre>

<p>Library introduction (The parts used in this pipeline):</p>

<ul>
  <li><strong>readxl</strong>: read in data in Excel file.</li>
  <li><strong>tidyverse</strong>: help manage the data frame in tidy sentences.</li>
  <li><strong>janitor</strong>: clean the column names.</li>
  <li><strong>ggplot2</strong>: create plots.</li>
  <li><strong>tidytext</strong>: import stop words data for text analysis and get word
sentiment dictionary.</li>
  <li><strong>wordcloud2</strong>: create word cloud graph.</li>
  <li><strong>RColorBrewer</strong>: set color palette for graphes.</li>
</ul>

<h4 id="read-in-raw-data-and-make-the-column-names">Read in raw data and make the column names.</h4>

<pre><code class="language-{r}">for(i in seq(2000,2009,1)){
  df &lt;- read_excel("Analysis Exercise.xls", sheet = as.character(i))
  names(df) &lt;- df[1,]
  df &lt;- df[-1,] %&gt;%
    clean_names() %&gt;%
    mutate(year = i)
  assign(paste0("df_", i), df)
}
</code></pre>

<p>In this Excel file, the data of different years was divided into sub-tables, therefore, I need to read in them one by one.</p>

<p>And the column names in each table were not in the first row but in the second row. So I removed the first row and transferred the second row to be the column names. Then, I used the <code class="highlighter-rouge">clean_names()</code> function to make the names lowercase without blank space.</p>

<p>The function <code class="highlighter-rouge">assign</code> can help me use different names to reserve the data.</p>

<p>After that, I merged all of the data.</p>

<pre><code class="language-{r}">df &lt;-
  bind_rows(df_2000, df_2001, df_2002, df_2003, df_2004, df_2005, df_2006, df_2007, df_2008, df_2009)
</code></pre>

<p>Import the stop words for text analysis in the EDA part.</p>

<pre><code class="language-{r}">data("stop_words")
</code></pre>

<h2 id="20-feature-engineering">20-feature-engineering</h2>

<p>This data set is clean enough and I don’t need to clean the data as normal.</p>

<p>Basic feature engineering on raw merged data:</p>

<pre><code class="language-{r}">df &lt;- df %&gt;%
  mutate(weeks_at_number_1 = as.integer(weeks_at_number_1),
         weeks_top_10 = as.integer(weeks_top_10),
         weeks_top_25 = as.integer(weeks_top_25),
         weeks_top_50 = as.integer(weeks_top_50),
         peak_position = as.integer(peak_position),
         bonus_weeks = as.integer(bonus_weeks),
         sub_points = as.integer(sub_points),
         peak_points = as.integer(peak_points),
         total_points = as.integer(total_points),
         peak_year = as.integer(peak_year),
         debut_date = as.integer(debut_date),
         debut_date = as.Date(debut_date, origin="1899-12-30"),
         peak_date = as.integer(peak_date),
         peak_date = as.Date(peak_date, origin="1899-12-30"),
         weeks_to_reach_peak = as.integer(weeks_to_reach_peak),
         year=as.factor(year)
         )
</code></pre>

<p>In this chunk, I only need to make all of the columns have the right data
type.</p>

<p><strong>Hint:</strong> In the date part, because Excel save the date by count the
distance between the date and 1900-01-01, the date columns in the raw
data are the days. I need to transfer them to be the real date. The
<code class="highlighter-rouge">origin</code> attribute should be 1900-01-01, but due to 1900-leap-year-bug
of Excel, use 1899-12-30 can get the right answer.</p>

<h2 id="30-exploratory-data-analysis">30-exploratory-data-analysis</h2>

<p>In this part, I will answer the following questions to finish the
exploratory data analysis(EDA) part.</p>

<h4 id="what-percent-of-songs-that-chart-never-make-the-top-10">What percent of songs that chart never make the Top 10?</h4>

<p>For all years:</p>

<pre><code class="language-{r}">never_top10 &lt;- df %&gt;%
  filter(weeks_top_10 == 0)
nrow(never_top10)/nrow(df)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.6802455
</code></pre></div></div>

<p>Time series:</p>

<pre><code class="language-{r}">never_top10_year &lt;- df %&gt;%
  filter(weeks_top_10 == 0) %&gt;%
  group_by(year) %&gt;%
  summarise(never_top10_number = n())

all_year &lt;- df %&gt;%
  group_by(year) %&gt;%
  summarise(whole_number = n())

never_top10_year["whole_number"] &lt;- all_year["whole_number"]
never_top10_year %&gt;%
  mutate(never_top10_ratio = never_top10_number/whole_number) %&gt;%
  ggplot() +
  geom_col(aes(x=year, y=never_top10_ratio),fill="#125FA0", width = 0.7)+
  theme_classic()+
  labs(x="\nYear", y="Ratio of Never-Top10\n")
</code></pre>

<p><img src="https://i.postimg.cc/0j7gsVWT/unnamed-chunk-7-1.png" alt="" /></p>

<h4 id="what-were-the-top-10-songs-of-the-decade-2000-2009">What were the top 10 songs of the decade 2000-2009?</h4>

<pre><code class="language-{r}">df %&gt;%
  arrange(desc(total_points)) %&gt;%
  select(song_title, artist, year, total_points) %&gt;%
  head(10)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 10 x 4
##    song_title               artist                       year  total_points
##    &lt;chr&gt;                    &lt;chr&gt;                        &lt;fct&gt;        &lt;int&gt;
##  1 GLAMOROUS                FERGIE featuring LUDACRIS    2007          1335
##  2 BEFORE HE CHEATS         UNDERWOOD, CARRIE            2007          1192
##  3 NO SUCH THING            MAYER, JOHN                  2002          1167
##  4 CITY LOVE                MAYER, JOHN                  2003          1167
##  5 VIDEO                    INDIA.ARIE                   2002          1129
##  6 WHERE IS THE LOVE?       BLACK EYED PEAS featuring J… 2003          1111
##  7 TWO WEEKS FROM TWENTY    YELLOWCARD                   2005          1111
##  8 AMERICAN BOY             ESTELLE featuring KANYE WEST 2008          1072
##  9 TIME OF YOUR LIFE (GOOD… GREEN DAY                    2006          1040
## 10 SOMEONE TO CALL MY LOVER JACKSON, JANET               2001          1012
</code></pre></div></div>

<h4 id="who-was-the-top-artist-of-the-decade-2000-2009">Who was the top artist of the decade 2000-2009?</h4>

<p>(Who were the top 10 artists of the decade 2000-2009?)</p>

<pre><code class="language-{r}">df %&gt;%
  group_by(artist) %&gt;%
  summarise(sum_total_points = sum(total_points, na.rm = TRUE)) %&gt;%
  arrange(desc(sum_total_points)) %&gt;%
  head(10)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 10 x 2
##    artist             sum_total_points
##    &lt;chr&gt;                         &lt;int&gt;
##  1 MAYER, JOHN                    6861
##  2 JACKSON, JANET                 6049
##  3 PANIC AT THE DISCO             4572
##  4 BLACK EYED PEAS                4481
##  5 CAREY, MARIAH                  4470
##  6 GREEN DAY                      4378
##  7 CLARKSON, KELLY                4016
##  8 UNDERWOOD, CARRIE              3762
##  9 PINK                           3668
## 10 MAROON 5                       3604
</code></pre></div></div>

<h4 id="based-on-the-chart-data-what-artists-would-you-call-the-beatles-of-the-decade-2000-2009">Based on the chart data, what artist(s) would you call “The Beatles” of the decade 2000-2009?</h4>

<p>Actually, this question is really difficult to answer, because “The
Beatles” has various meanings according to different interpretations.</p>

<p>However, we can try to give some directions by analyzing the number of
songs on the chart and the mean point of the songs on the chart of each artist.</p>

<pre><code class="language-{r}">df %&gt;%
  group_by(artist) %&gt;%
  summarise(song_number = n()) %&gt;%
  arrange(desc(song_number)) %&gt;%
  head(10)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 10 x 2
##    artist              song_number
##    &lt;chr&gt;                     &lt;int&gt;
##  1 SPEARS, BRITNEY              21
##  2 PINK                         18
##  3 CAREY, MARIAH                14
##  4 CLARKSON, KELLY              14
##  5 EMINEM                       14
##  6 BEYONCE                      13
##  7 LAVIGNE, AVRIL               13
##  8 AGUILERA, CHRISTINA          12
##  9 MAYER, JOHN                  12
## 10 NELLY                        12
</code></pre></div></div>

<pre><code class="language-{r}">df %&gt;%
  group_by(artist) %&gt;%
  summarise(mean_total_points = mean(total_points)) %&gt;%
  arrange(desc(mean_total_points)) %&gt;%
  head(10)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 10 x 2
##    artist                                      mean_total_points
##    &lt;chr&gt;                                                   &lt;dbl&gt;
##  1 FERGIE featuring LUDACRIS                               1335
##  2 BLACK EYED PEAS featuring JUSTIN TIMBERLAKE             1111
##  3 ESTELLE featuring KANYE WEST                            1072
##  4 LOS LONELY BOYS                                          928
##  5 LOPEZ, JENNIFER featuring JA RULE                        861
##  6 SHAGGY featuring RICARDO DUCENT                          829
##  7 FOXX, JAMIE featuring T-PAIN                             808
##  8 POWTER, DANIEL                                           779
##  9 INDIA.ARIE                                               764.
## 10 EVE featuring GWEN STEFANI                               757
</code></pre></div></div>

<h4 id="what-was-the-most-commonly-used-word-in-a-song-title-for-the-decade-2000-2009">What was the most commonly used word in a song title for the decade 2000-2009?</h4>

<p>For this question, due to there are many special symbols in the song
title, I need to clean the special patterns in the title.</p>

<pre><code class="language-{r}">title_df &lt;- df["song_title"]
title_df &lt;- title_df %&gt;% mutate(song_title = str_to_lower(song_title))
title_df$song_title &lt;- gsub(pattern = "\\(", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "\\)", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = ",", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "n't", replacement =" not ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "'s", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "'re", replacement =" are ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "'m", replacement =" am ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "\\\"", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "\\.", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "-", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "_", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "!", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "\\?", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "…", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "[0-9]", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "/", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "&amp;", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = "#", replacement =" ", title_df$song_title)
title_df$song_title &lt;- gsub(pattern = " +", replacement =" ", title_df$song_title)
</code></pre>

<p>Then make the data frame become list, which can help the following
steps.</p>

<pre><code class="language-{r}">title_list &lt;- title_df[["song_title"]]
</code></pre>

<p>Split all of the title into scattered words.</p>

<pre><code class="language-{r}">title_words &lt;- data.frame()
count &lt;- 1
for (i in title_list) {
  title_split &lt;- str_split(string = i, pattern = " ")
  for(j in title_split[[1]]){
    title_words[count,1] &lt;- j
    count &lt;- count + 1
  }
}
names(title_words) &lt;- "word"
</code></pre>

<p>Clean the different forms of the same word.</p>

<pre><code class="language-{r}">title_words &lt;- title_words %&gt;%
  mutate(word = case_when(word == "girls" ~ "girl",
                          word == "angels" ~ "angel",
                          word == "days" ~ "day",
                          word == "lovin'" ~ "love",
                          word == "loving" ~ "love",
                          word == "loved'" ~ "love",
                          word == "luv" ~ "love",
                          word == "waiting" ~ "wait",
                          word == "does" ~ "do",
                          word == "lights" ~ "light",
                          word == "things" ~ "thing",
                          word == "comes" ~ "come",
                          word == "dancing" ~ "dance",
                          word == "dancin'" ~ "dance",
                          word == "boys" ~ "boy",
                          word == "burning" ~ "burn",
                          word == "burnin'" ~ "burn",
                          word == "calle" ~ "call",
                          word == "called" ~ "call",
                          word == "calling" ~ "call",
                          word == "call" ~ "call",
                          TRUE ~ word))
</code></pre>

<p>Count the number of each word.</p>

<pre><code class="language-{r}">word_count &lt;- title_words %&gt;%
  filter(word != "") %&gt;%
  anti_join(stop_words,by = "word") %&gt;%
  group_by(word) %&gt;%
  summarise(number = n()) %&gt;%
  arrange(desc(number)) %&gt;%
  mutate(word = str_to_upper(word))
word_count
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1,192 x 2
##    word  number
##    &lt;chr&gt;  &lt;int&gt;
##  1 LOVE      87
##  2 GIRL      43
##  3 TIME      29
##  4 LIFE      21
##  5 DAY       20
##  6 WORLD     15
##  7 BABY      14
##  8 DANCE     14
##  9 ROCK      14
## 10 SONG      14
## # … with 1,182 more rows
</code></pre></div></div>

<p>Generate the word cloud by <code class="highlighter-rouge">wordcloud2</code> function.</p>

<pre><code class="language-{r}">wordcloud2(head(word_count,100),
           size = 1,
           fontFamily = "Montserrat",
           fontWeight = "Bold",
           minRotation = -pi/6,
           maxRotation = -pi/6,
           rotateRatio = 1,
           color = "#125FA0")
</code></pre>

<iframe src="https://waittim.github.io/gallery/song-wordcloud.html" frameborder="0" width="700" height="423" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

<h4 id="sentiment-analysis-of-titles">Sentiment analysis of titles</h4>

<p>In order to analyze the sentiment of the words in the titles, I got the
stop words(meaningless words) dictionary and sentiment dictionary from
the <code class="highlighter-rouge">tidytext</code> library.</p>

<pre><code class="language-{r}">sentiments &lt;- get_sentiments("nrc")

df_sentiments &lt;- title_words %&gt;%
  filter(word != "") %&gt;%
  anti_join(stop_words,by = "word") %&gt;%
  left_join(sentiments)
</code></pre>

<pre><code class="language-{r}">df_sentiments_filtered &lt;- df_sentiments %&gt;%
  filter(!is.na(sentiment)) %&gt;%
  group_by(sentiment) %&gt;%
  summarize(n = n()) %&gt;%
  arrange(desc(n))
</code></pre>

<p>After removed the stop word, I counted the number of each word in the titles.</p>

<pre><code class="language-{r}">df_sentiments_filtered %&gt;%
  ggplot(aes(x = reorder(sentiment, n, function(n) -n), y = n)) +
  geom_bar(stat = "identity",fill="#125FA0", width = 0.7) +
  theme_classic() +
  labs(x = "\nSentiments", y="number\n")
</code></pre>

<p><img src="https://i.postimg.cc/hPqWrqhc/unnamed-chunk-19-1.png" alt="" /></p>

<p>And we can also count what is the percentage of positive words in the
words that have sentiments.</p>

<pre><code class="language-{r}">words_positive &lt;- df_sentiments %&gt;%
  filter(sentiment == "positive") %&gt;%
  group_by(word) %&gt;%
  summarise(n=n())

words_all_sentiment &lt;- df_sentiments %&gt;%
  filter(!is.na(sentiment)) %&gt;%
  group_by(word) %&gt;%
  summarize(n = n()) %&gt;%
  arrange(desc(n))

nrow(words_positive)/nrow(words_all_sentiment)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.4294671
</code></pre></div></div>

<h4 id="who-spent-the-most-weeks-at-1-for-the-decade-2000-2009">Who spent the most weeks at #1 for the decade 2000-2009?</h4>

<pre><code class="language-{r}">df %&gt;%
  group_by(artist) %&gt;%
  summarise(top1_time_sum = sum(weeks_at_number_1)) %&gt;%
  arrange(desc(top1_time_sum)) %&gt;%
  head(1)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1 x 2
##   artist         top1_time_sum
##   &lt;chr&gt;                  &lt;int&gt;
## 1 JACKSON, JANET            39
</code></pre></div></div>

<p>And there are the songs belong to this artist.</p>

<pre><code class="language-{r}">df %&gt;%
  filter(artist == "JACKSON, JANET",
         weeks_at_number_1 != 0) %&gt;%
  arrange(desc(weeks_at_number_1)) %&gt;%
  select(song_title, artist, year, weeks_at_number_1)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 6 x 4
##   song_title                            artist       year  weeks_at_number…
##   &lt;chr&gt;                                 &lt;chr&gt;        &lt;fct&gt;            &lt;int&gt;
## 1 SOMEONE TO CALL MY LOVER              JACKSON, JA… 2001                10
## 2 ALL FOR YOU                           JACKSON, JA… 2001                10
## 3 "DOESN'T REALLY MATTER (from \"NUTTY… JACKSON, JA… 2000                 8
## 4 FEEDBACK                              JACKSON, JA… 2008                 6
## 5 SPECIAL                               JACKSON, JA… 2000                 3
## 6 LUV                                   JACKSON, JA… 2008                 2
</code></pre></div></div>

<h4 id="what-song-spent-the-most-weeks-at-1-for-the-decade-2000-2009">What song spent the most weeks at #1 for the decade 2000-2009?</h4>

<pre><code class="language-{r}">df %&gt;%
  arrange(desc(weeks_at_number_1)) %&gt;%
  select(song_title, artist, year, weeks_at_number_1) %&gt;%
  head(1)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1 x 4
##   song_title    artist      year  weeks_at_number_1
##   &lt;chr&gt;         &lt;chr&gt;       &lt;fct&gt;             &lt;int&gt;
## 1 NO SUCH THING MAYER, JOHN 2002                 13
</code></pre></div></div>

<h4 id="what-song-peaked-at-1-the-quickest-in-the-decade-2000-2009">What song peaked at #1 the quickest in the decade 2000-2009?</h4>

<pre><code class="language-{r}">df %&gt;%
  filter(weeks_at_number_1 != 0) %&gt;%
  arrange(weeks_to_reach_peak) %&gt;%
  select(song_title, artist, year, weeks_at_number_1, weeks_to_reach_peak, debut_date, peak_date) %&gt;%
  head(1)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1 x 7
##   song_title artist year  weeks_at_number… weeks_to_reach_… debut_date
##   &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;            &lt;int&gt;            &lt;int&gt; &lt;date&gt;    
## 1 SOMEONE T… JACKS… 2001                10                2 2001-07-22
## # … with 1 more variable: peak_date &lt;date&gt;
</code></pre></div></div>

<h4 id="what-song-took-the-longest-to-reach-1-in-the-decade-2000-2009">What song took the longest to reach #1 in the decade 2000-2009?</h4>

<pre><code class="language-{r}">df %&gt;%
  filter(weeks_at_number_1 != 0) %&gt;%
  arrange(desc(weeks_to_reach_peak)) %&gt;%
  select(song_title, artist, year, weeks_at_number_1, weeks_to_reach_peak, debut_date, peak_date) %&gt;%
  head(1)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 1 x 7
##   song_title artist year  weeks_at_number… weeks_to_reach_… debut_date
##   &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;            &lt;int&gt;            &lt;int&gt; &lt;date&gt;    
## 1 BEFORE HE… UNDER… 2007                 3               31 2006-11-05
## # … with 1 more variable: peak_date &lt;date&gt;
</code></pre></div></div>

<h4 id="solo-men-solo-women-groups-for-the-decade-2000-2009---design-a-graphic-that-shows-the-distribution-of-songs-hitting-1">Solo men, solo women, groups for the decade 2000-2009 - design a graphic that shows the distribution of songs hitting #1</h4>

<p>The solo artists have their full name in the data by the format as
“LastName, FirstName”, as a result, we can tell whether the data is a
single person name by the presence of a comma.</p>

<pre><code class="language-{r}">df %&gt;%
  mutate(solo_group = case_when(str_detect(string = artist, pattern = ",") ~ "solo",
                                TRUE ~ "group")) %&gt;%
  mutate(solo_group = as.factor(solo_group)) %&gt;%
  filter(weeks_at_number_1 != 0) %&gt;%
  group_by(solo_group) %&gt;%
  summarise(number = n())
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 x 2
##   solo_group number
##   &lt;fct&gt;       &lt;int&gt;
## 1 group          92
## 2 solo           84
</code></pre></div></div>

<p>Actually, there is no built-in pie chart function in <code class="highlighter-rouge">ggplot2</code>. But we
can use bar chart function then twisting the y-axis to the polar
coordinate system to create a pie chart.</p>

<pre><code class="language-{r}">df %&gt;%
  mutate(solo_group = case_when(str_detect(string = artist, pattern = ",") ~ "solo",
                                TRUE ~ "group")) %&gt;%
  mutate(solo_group = as.factor(solo_group)) %&gt;%
  filter(weeks_at_number_1 != 0) %&gt;%
  ggplot()+
  geom_bar(aes(x=1, fill = solo_group))+
  coord_polar(theta = "y")+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        legend.title = element_blank(),
        panel.background = element_blank()
        )+
  scale_fill_brewer(palette = "Paired")
</code></pre>

<p><img src="https://i.postimg.cc/fWdQmbz8/unnamed-chunk-27-1.png" alt="" /></p>

<h4 id="solo-men-solo-women-groups-for-the-decade-2000-2009---design-a-graphic-that-shows-the-distribution-of-songs-hitting-the-top-10">Solo men, solo women, groups for the decade 2000-2009 - design a graphic that shows the distribution of songs hitting the Top 10</h4>

<pre><code class="language-{r}">df %&gt;%
  mutate(solo_group = case_when(str_detect(string = artist, pattern = ",") ~ "solo",
                                TRUE ~ "group")) %&gt;%
  mutate(solo_group = as.factor(solo_group)) %&gt;%
  filter(weeks_top_10 != 0) %&gt;%
  group_by(solo_group) %&gt;%
  summarise(number = n())
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 2 x 2
##   solo_group number
##   &lt;fct&gt;       &lt;int&gt;
## 1 group         318
## 2 solo          255
</code></pre></div></div>

<pre><code class="language-{r}">df %&gt;%
  mutate(solo_group = case_when(str_detect(string = artist, pattern = ",") ~ "solo",
                                TRUE ~ "group")) %&gt;%
  mutate(solo_group = as.factor(solo_group)) %&gt;%
  filter(weeks_top_10 != 0) %&gt;%
  ggplot()+
  geom_bar(aes(x=1, fill = solo_group))+
  coord_polar(theta = "y")+
  theme(axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        legend.title = element_blank(),
        panel.background = element_blank()
        )+
  scale_fill_brewer(palette = "Paired")
</code></pre>

<p><img src="https://i.postimg.cc/ncY8SwQ7/unnamed-chunk-29-1.png" alt="" /></p>

<h4 id="what-song-spent-the-most-time-on-the-charts-in-the-decade-2000-2009">What song spent the most time on the charts in the decade 2000-2009)</h4>

<pre><code class="language-{r}">df %&gt;%
  arrange(desc(weeks_top_50)) %&gt;%
  select(song_title, artist, year, weeks_top_50) %&gt;%
  head(3)
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## # A tibble: 3 x 4
##   song_title                      artist                 year  weeks_top_50
##   &lt;chr&gt;                           &lt;chr&gt;                  &lt;fct&gt;        &lt;int&gt;
## 1 TIME OF YOUR LIFE (GOOD RIDDAN… GREEN DAY              2006            65
## 2 BEFORE HE CHEATS                UNDERWOOD, CARRIE      2007            57
## 3 GLAMOROUS                       FERGIE featuring LUDA… 2007            50
</code></pre></div></div>

<p>Actually, TIME OF YOUR LIFE (GOOD RIDDANCE) never be the top 1. A sad
story.</p>

<h4 id="is-there-a-correlation-between-weeks-spent-on-the-chart-and-weeks-at-1">Is there a correlation between weeks spent on the chart and weeks at #1?</h4>

<pre><code class="language-{r}">cor(x = df[["weeks_at_number_1"]],
    y = df[["weeks_top_50"]])
</code></pre>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## [1] 0.471703
</code></pre></div></div>

<pre><code class="language-{r}">df %&gt;%
  ggplot(aes(x=weeks_at_number_1, y=weeks_top_50))+
  geom_jitter(alpha = 0.3, color = "dodgerblue4")+
  geom_smooth(color = "dodgerblue4", se = FALSE)+
  theme_classic()+
  labs(x="\nWeeks at Top 1", y="Weeks at Top 50\n")
</code></pre>

<p><img src="https://i.postimg.cc/7ZxFFMgR/unnamed-chunk-32-1.png" alt="" /></p>

<p><em>Hint: Project GitHub page: <a href="https://github.com/waittim/Cashbox-Magazine-song-records-Analysis">Cashbox-Magazine-song-records-Analysis</a></em></p>
:ET