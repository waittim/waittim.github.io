I";<p>Absolute error and relative error have a little bit difference on calculation but the difference really makes an essential change. Absolute error will be influenced by the samples size but relative error can show the real error without huge bias.</p>

<blockquote>
  <p>when used as a measure of precision—is the ratio of the absolute error of a measurement to the measurement being taken. In other words, this type of error is relative to the size of the item being measured. RE is expressed as a percentage and has no units.</p>
</blockquote>

<p><em>From <a href="https://www.statisticshowto.datasciencecentral.com/relative-error/">Statistics How To</a></em></p>

<h2 id="absolute-error">Absolute Error</h2>
<p>absolute error = |p̂−p|</p>

<blockquote>
  <p>The difference between the measured or inferred value of a quantity x_0 and its actual value x.</p>
</blockquote>

<p>Let’s create a table to save 14*5 results of our simulation first.</p>
<pre><code class="language-{r}">n &lt;- rep(NA, 14)
for(i in 1:14){n[i] &lt;- 2^(i+1)}
T &lt;- matrix(NA,14,5)
p &lt;- c(0.01,0.05,0.10,0.25,0.5)
</code></pre>

<p>Than generate 1 or 0 randomly for 1000 times for each situation and calculate the absolute error.</p>
<pre><code class="language-{r}">for(x in 1:length(p)){
  for(y in 1:length(n)){
    TS &lt;- rep(NA,10000)
    for(m in 1:10000){
      TS[m] &lt;- abs(rbinom(1,n[y],p[x])/n[y]-p[x])
    }
    T[y,x] &lt;- mean(TS)
  }
}
</code></pre>

<p>Change the y-scale to log_10.</p>
<pre><code class="language-{r}">T &lt;- log10(T)
</code></pre>

<p>In the end, plot the graph to show the relationship between p and absolute error.</p>
<pre><code class="language-{r}">plot(T[,5],xlim=c(0,14),ylim=range(T),col="red",type="b",xaxt="n",xlab="N(log_2 scale)",ylab="Absolute Error",pch=16, lwd=3)
lines(T[,2],col="purple",type="b",pch=16, lwd=3)
lines(T[,3],col="blue",type="b",pch=16, lwd=3)
lines(T[,4],col="green",type="b",pch=16, lwd=3)
lines(T[,1],col="gray",type="b",pch=16, lwd=3)

lname &lt;- c("0.01","0.05","0.10","0.25","0.50")
lname_p &lt;- paste0("p = ",lname)
xname &lt;- c("4","8","16","32","64","128","256","512","1024","2048","4096","8192","16384","32768")

axis(1, at=1:14,las=2, lab=xname)
text(1,T[1,],lname_p,pos=2,cex=0.6)
</code></pre>
<p><img src="https://i.loli.net/2019/12/22/6yheRBQ3HIMnDcd.png" alt="" /></p>

<p>Absolute error is just the absolute value of the value you have minus expected value. In this simulation, you culculated the absolute error 10000 times and get the mean value of them in every situation.
When we transfer the y scale to log_10, it is obvious that the x &amp; y have linear connection.
The p is higher, the absolute error is bigger.</p>

<h1 id="relative-error">Relative Error</h1>
<p>relative error = |p̂−p|/p.</p>

<p>Then do the same thing as before but when we calculate the error, use absolute error divide by p value.
Plot the graph too.</p>

<pre><code class="language-{r}">n &lt;- rep(NA, 14)
for(i in 1:14){n[i] &lt;- 2^(i+1)}

T2 &lt;- matrix(NA,14,5)
p &lt;- c(0.01,0.05,0.10,0.25,0.5)

for(x in 1:length(p)){
  for(y in 1:length(n)){
    T2S &lt;- rep(NA,10000)
    for(m in 1:10000){
      T2S[m] &lt;- abs(rbinom(1,n[y],p[x])/n[y]-p[x])/p[x]
    }
    # T2[y,x] &lt;- abs(rbinom(1,n[y],p[x])/n[y]-p[x])/p[x]
    T2[y,x] &lt;- mean(T2S)
  }
}

T2 &lt;- log10(T2)

xname &lt;- c("4","8","16","32","64","128","256","512","1024","2048","4096","8192","16384","32768")
lname &lt;- c("0.01","0.05","0.10","0.25","0.50")
lname_p &lt;- paste0("p = ",lname)

plot(T2[,1],xlim=c(0,14),ylim=range(T2),col="red",type="b",pch=16,xaxt="n",xlab="N(log_2 scale)",ylab="Relative Error", lwd=3)
lines(T2[,2],col="purple",type="b",pch=16, lwd=3)
lines(T2[,3],col="blue",type="b",pch=16, lwd=3)
lines(T2[,4],col="green",type="b",pch=16, lwd=3)
lines(T2[,5],col="gray",type="b",pch=16, lwd=3)
axis(1, at=1:14,las=2, lab=xname)
text(1,T2[1,],lname_p,pos=2,cex=0.6)
</code></pre>
<p><img src="https://i.loli.net/2019/12/22/lryCYGkREIN6dWx.png" alt="" /></p>

<p>Again, compare with absolute error, if you want to calculate relative error, the only thing you need to do is use the absolute error divide by p, the value you have. This process keep the influence of the value size, and focus on the error itself.
When we change the y scale into log_10, the xy relationship is also linear. But the bigger p we have, the smaller relative error we get.</p>
:ET