I"g0<h1 id="introduction">Introduction</h1>

<p>The median is an important quantity in data analysis. It represents the middle value of the data distribution. Estimates of the median, however, have a degree of uncertainty because (a) the estimates are calculated from a finite sample and (b) the data distribution of the underlying data is generally unknown. One important roles of a data scientist is to quantify and to communicate the degree of uncertainty in his or her data analysis.</p>

<p>This time, we are going to find out what can make our sample distribution more precise during the simulation.</p>

<pre><code class="language-{r}">knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(reshape2)
</code></pre>

<h1 id="standard-normal-distribution">Standard Normal Distribution</h1>

<p>First, we need to set up the initial parameters. For every simulation process, we will generate 200 values base on the standard normal distribution, and we will generate them for 5000 times.</p>

<p>Therefore, set the sample size as 200, test number is 5000.</p>

<pre><code class="language-{r}">sample_size &lt;- 200
test_num &lt;- 5000
</code></pre>

<p>Then let’s create a function for find out the quantile values of each test and output them as sequences.</p>
<pre><code class="language-{r}">find_quantile_value &lt;- function(fn,sample_size, quantile_position){
  sample &lt;- fn(sample_size)
  qtseq &lt;- quantile(sample, seq(0.05,0.95,0.05))
  qtseq[[quantile_position]]
}
</code></pre>

<p>In order to store the values of each quantile, we can create a data frame. For there are 19 quantiles and 5000 tests, the data frame should be a 5000*19 table.
Then use for loop traverse each test and each quantile.</p>
<pre><code class="language-{r}">sml_results &lt;- as.data.frame(matrix(NA, nrow = test_num, ncol = 19))

for(i in 1:nrow(sml_results)){
  for(q in 1:ncol(sml_results)){
    sml_results[i,q] &lt;- find_quantile_value(rnorm,sample_size, q)
  }
}
</code></pre>

<p>Now we need to find the middle 95% length of the distributions of each qutaile value.</p>
<pre><code class="language-{r}">length_list &lt;- rep(NA,ncol(sml_results))
for(q in 1:ncol(sml_results)){
  quantile_2.5_97.5&lt;- quantile(sml_results[,q], c(0.025, 0.975))
  length_list[q] &lt;- quantile_2.5_97.5[[2]]-quantile_2.5_97.5[[1]]
}

</code></pre>

<p>Save the data we got before into a data frame and plot them.</p>
<pre><code class="language-{r}">length_df &lt;- as.data.frame(matrix(ncol = 2, nrow = length(length_list)))
names(length_df) &lt;- c("quantile_position","mid95_length")
length_df[,1] &lt;- seq(0.05,0.95,0.05)
length_df[,2] &lt;- length_list
ggplot(length_df,aes(x=quantile_position,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of normal distribution")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )+
  scale_y_continuous(name = "Length")
</code></pre>

<p>as we can see, when the quantile is approaching 50%, the length is going lower. It means that when the quantile is approaching 50%, simulation error is lower. It means when the quantile is 50%, it has the best precision.</p>

<p>In other words, when the quantile is 50%, the median have the tightest sampling distribution.</p>

<p>Then, we need to transfer the x-axis from quantile to the density values of the original distribution. In this part, it should be standard normal distribution.</p>
<pre><code class="language-{r}">length_d_df &lt;- length_df %&gt;%
  mutate(density=dnorm(qnorm(quantile_position)))

ggplot(length_d_df, aes(x=density,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of normal distribution by density", x= "Density",y="Length")
</code></pre>

<p>In this graph, we can find when density is bigger, the simulation error is lower.</p>

<h1 id="exponential-distribution">Exponential Distribution</h1>

<p>Distribution 2 is the exponential distribution with rate = 1.</p>

<p>As we did before, calculate the values of each quantile and each test then plot the graph.</p>

<pre><code class="language-{r}">
for(i in 1:nrow(sml_results)){
  for(q in 1:ncol(sml_results)){
    sml_results[i,q] &lt;- find_quantile_value(rexp,sample_size, q)
  }
}

length_list &lt;- rep(NA,ncol(sml_results))
for(q in 1:ncol(sml_results)){
  quantile_2.5_97.5&lt;- quantile(sml_results[,q], c(0.025, 0.975))
  length_list[q] &lt;- quantile_2.5_97.5[[2]]-quantile_2.5_97.5[[1]]
}

length_df &lt;- as.data.frame(matrix(ncol = 2, nrow = length(length_list)))
names(length_df) &lt;- c("quantile_position","mid95_length")
length_df[,1] &lt;- seq(0.05,0.95,0.05)
length_df[,2] &lt;- length_list
ggplot(length_df,aes(x=quantile_position,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of exponential distribution")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )+
  scale_y_continuous(name = "Length")

</code></pre>

<p>For this exponential distribution, when quantile is bigger, the error of simulation is bigger.</p>

<p>In other words, when the quantile is 5%, the median have the tightest sampling distribution.</p>

<p>And when the Density is higher, the error is smaller.</p>

<pre><code class="language-{r}">length_d_df &lt;- length_df %&gt;%
  mutate(density=dexp(qexp(quantile_position)))

ggplot(length_d_df, aes(x=density,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of exponential distribution by density", x= "Density",y="Length")
</code></pre>

<h1 id="mixture-distribution-3">Mixture Distribution 3</h1>

<p>Distribution 3 is a mixture distribution defined by these functions.</p>
<pre><code class="language-{r}">rf3 &lt;- function(N){
  G &lt;- sample(0:2, N, replace = TRUE, prob = c(5,3,2))
  (G==0)*rnorm(N) + (G==1)*rnorm(N,4) + (G==2)*rnorm(N,-4,2)
}

pf3 &lt;- function(x){
  .5*pnorm(x) + .3*pnorm(x,4) + .2*pnorm(x,-4,2)
}

df3 &lt;- function(x){
  .5*dnorm(x) + .3*dnorm(x,4) + .2*dnorm(x,-4,2)
}
</code></pre>

<p>And just like we did in previous chunks, plot the middle 95% length of the quantiles.</p>

<pre><code class="language-{r}">for(i in 1:nrow(sml_results)){
  for(q in 1:ncol(sml_results)){
    sml_results[i,q] &lt;- find_quantile_value(rf3,sample_size, q)
  }
}

length_list &lt;- rep(NA,ncol(sml_results))
for(q in 1:ncol(sml_results)){
  quantile_2.5_97.5&lt;- quantile(sml_results[,q], c(0.025, 0.975))
  length_list[q] &lt;- quantile_2.5_97.5[[2]]-quantile_2.5_97.5[[1]]
}

length_df &lt;- as.data.frame(matrix(ncol = 2, nrow = length(length_list)))
names(length_df) &lt;- c("quantile_position","mid95_length")
length_df[,1] &lt;- seq(0.05,0.95,0.05)
length_df[,2] &lt;- length_list
ggplot(length_df,aes(x=quantile_position,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of given mixture distribution 3")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )+
  scale_y_continuous(name = "Length")
</code></pre>

<p>Definitely, when the quantile is 40%, the median have the tightest sampling distribution.</p>

<p>We don’t have the qf3 function, therefore we need to use pf3 function calculate the values when their counterpart quantile is setted. And the other part is same as previous chunks.</p>

<pre><code class="language-{r}">pf3 &lt;- function(x){
  .5*pnorm(x) + .3*pnorm(x,4) + .2*pnorm(x,-4,2)
}

quantile_seq &lt;- seq(0.05,0.95,0.05)
qf3_seq &lt;- rep(NA, length(quantile_seq))
for(i in seq_along(quantile_seq)){
qf3_seq[i] &lt;- uniroot(function(x){pf3(x)-quantile_seq[i]}, c(-100,100))[[1]]
}

length_d_df &lt;- length_df %&gt;%
  mutate(density=df3(qf3_seq))

ggplot(length_d_df, aes(x=density,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of given mixture distribution 3 by density", x= "Density",y="Length")
</code></pre>

<h1 id="mixture-distribution-4">Mixture Distribution 4</h1>

<p>Mixture Distribution 4 is the following mixture distribution.</p>

<pre><code class="language-{r}">rf4 &lt;- function(N){
  G &lt;- sample(0:1, N, replace = TRUE)
  (G==0)*rbeta(N,5,1) + (G==1)*rbeta(N,1,5)
}
</code></pre>

<p>As previous chunks, we can plot the length of each quantile.</p>

<pre><code class="language-{r}">for(i in 1:nrow(sml_results)){
  for(q in 1:ncol(sml_results)){
    sml_results[i,q] &lt;- find_quantile_value(rf4,sample_size, q)
  }
}

length_list &lt;- rep(NA,ncol(sml_results))
for(q in 1:ncol(sml_results)){
  quantile_2.5_97.5&lt;- quantile(sml_results[,q], c(0.025, 0.975))
  length_list[q] &lt;- quantile_2.5_97.5[[2]]-quantile_2.5_97.5[[1]]
}

length_df &lt;- as.data.frame(matrix(ncol = 2, nrow = length(length_list)))
names(length_df) &lt;- c("quantile_position","mid95_length")
length_df[,1] &lt;- seq(0.05,0.95,0.05)
length_df[,2] &lt;- length_list
ggplot(length_df,aes(x=quantile_position,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of given mixture distribution 4")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )+
  scale_y_continuous(name = "Length")

</code></pre>

<p>Definitely, when the quantile is 5% or 95%, the median have the tightest sampling distribution.</p>

<p>Base on the rf4 function we had, we can write the pf4 and df4 functions. After that, use the method we used plot the graph.</p>
<pre><code class="language-{r}">rf4 &lt;- function(N){
  G &lt;- sample(0:1, N, replace = TRUE)
  (G==0)*rbeta(N,5,1) + (G==1)*rbeta(N,1,5)
}

pf4 &lt;- function(x){
  .5*pbeta(x,5,1) + .5*pbeta(x,1,5)
}

df4 &lt;- function(x){
  .5*dbeta(x,5,1) + .5*dbeta(x,1,5)
}

quantile_seq &lt;- seq(0.05,0.95,0.05)
qf4_seq &lt;- rep(NA, length(quantile_seq))
for(i in seq_along(quantile_seq)){
qf4_seq[i] &lt;- uniroot(function(x){pf4(x)-quantile_seq[i]}, c(-100,100))[[1]]
}



length_d_df &lt;- length_df %&gt;%
  mutate(density=df4(qf4_seq))

ggplot(length_d_df, aes(x=density,y=mid95_length))+
  geom_point()+geom_line()+
  labs(title = "Length of middle 95% of given mixture distribution 4 by density", x= "Density",y="Length")
</code></pre>

<h1 id="other-tests">Other Tests</h1>

<p>In this part, we will focus on the situations that when sample size become 400, 800 and 1600.</p>

<p>Now use a for loop to generate all of the data given different sample sizes.</p>
<pre><code class="language-{r}">sample_size &lt;- c(400,800,1600)
test_num &lt;- 5000

length_df &lt;- as.data.frame(matrix(ncol = 1+length(sample_size), nrow = length(length_list)))
names(length_df) &lt;- c("quantile_position","400_mid95_length","800_mid95_length","1600_mid95_length")
length_df[,1] &lt;- seq(0.05,0.95,0.05)

for(n in seq_along(sample_size)){

  sml_results &lt;- as.data.frame(matrix(NA, nrow = test_num, ncol = 19))

  for(i in 1:nrow(sml_results)){
    for(q in 1:ncol(sml_results)){
      sml_results[i,q] &lt;- find_quantile_value(rnorm,sample_size[n], q)
    }
  }

  length_list &lt;- rep(NA,ncol(sml_results))
  for(q in 1:ncol(sml_results)){
    quantile_2.5_97.5&lt;- quantile(sml_results[,q], c(0.025, 0.975))
    length_list[q] &lt;- quantile_2.5_97.5[[2]]-quantile_2.5_97.5[[1]]
  }

  length_df[,1+n] &lt;- length_list
}
</code></pre>

<p>Than plot the graph of different sample size and compare them.</p>
<pre><code class="language-{r}">length_df %&gt;%
  melt(id = "quantile_position") %&gt;%
  ggplot()+
  geom_line(aes(x=quantile_position,y=value,color=variable))+
  labs(title = "Length of middle 95% of normal distribution given different sample sizes", y = "Length")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )
</code></pre>

<pre><code class="language-{r}">length_df %&gt;%
  mutate(density=dnorm(qnorm(quantile_position))) %&gt;%
  select(-quantile_position) %&gt;%
  melt(id = "density") %&gt;%
  ggplot()+
  geom_line(aes(x=density,y=value,color=variable))+
  labs(title = "Length of middle 95% of normal distribution given different sample sizes", y = "Length")+
  scale_x_continuous(
    name = "pth quantile",
    breaks = seq(0.05, 0.95, 0.05)
  )

</code></pre>

<p>Definitely, when the sample size is bigger, the error of simulation will be smaller.</p>

<p>In a word, when you have more simulation test, when the test number is increasing, the length will be smaller, what means the error of simulation is less than before.</p>
:ET